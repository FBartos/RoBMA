% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main.R
\name{RoBMA}
\alias{RoBMA}
\title{Estimate a Robust Bayesian Meta-Analysis}
\usage{
RoBMA(
  d = NULL,
  r = NULL,
  logOR = NULL,
  z = NULL,
  y = NULL,
  se = NULL,
  v = NULL,
  n = NULL,
  lCI = NULL,
  uCI = NULL,
  t = NULL,
  study_names = NULL,
  data = NULL,
  transformation = if (is.null(y)) "fishers_z" else "none",
  prior_scale = if (is.null(y)) "cohens_d" else "none",
  effect_direction = "positive",
  model_type = NULL,
  priors_effect = prior(distribution = "normal", parameters = list(mean = 0, sd = 1)),
  priors_heterogeneity = prior(distribution = "invgamma", parameters = list(shape = 1,
    scale = 0.15)),
  priors_bias = list(prior_weightfunction(distribution = "two.sided", parameters =
    list(alpha = c(1, 1), steps = c(0.05)), prior_weights = 1/12),
    prior_weightfunction(distribution = "two.sided", parameters = list(alpha = c(1, 1,
    1), steps = c(0.05, 0.1)), prior_weights = 1/12), prior_weightfunction(distribution =
    "one.sided", parameters = list(alpha = c(1, 1), steps = c(0.05)), prior_weights =
    1/12), prior_weightfunction(distribution = "one.sided", parameters = list(alpha =
    c(1, 1, 1), steps = c(0.025, 0.05)), prior_weights = 1/12),     
    prior_weightfunction(distribution = "one.sided", parameters = list(alpha = c(1, 1,
    1), steps = c(0.05, 0.5)), prior_weights = 1/12), prior_weightfunction(distribution =
    "one.sided", parameters = list(alpha = c(1, 1, 1, 1), steps = c(0.025, 0.05, 0.5)),
    prior_weights = 1/12), prior_PET(distribution = "Cauchy", parameters = list(0, 1),
    truncation = list(0, Inf), prior_weights = 1/4), prior_PEESE(distribution = "Cauchy",
    parameters = list(0, 5), truncation = list(0, Inf), prior_weights = 1/4)),
  priors_effect_null = prior(distribution = "point", parameters = list(location = 0)),
  priors_heterogeneity_null = prior(distribution = "point", parameters = list(location
    = 0)),
  priors_bias_null = prior_none(),
  chains = 3,
  sample = 5000,
  burnin = 2000,
  adapt = 500,
  thin = 1,
  parallel = FALSE,
  autofit = FALSE,
  autofit_control = set_autofit_control(),
  convergence_checks = set_convergence_checks(),
  save = "all",
  seed = NULL,
  silent = TRUE
)
}
\arguments{
\item{d}{a vector of effect sizes measured as Cohen's d.}

\item{r}{a vector of effect sizes measured as correlations.}

\item{logOR}{a vector of log odds ratios.}

\item{y}{a vector of unspecified effect sizes (note that effect size
transformations are unavailable with this type of input).}

\item{se}{a vector of standard errors of the effect sizes.}

\item{v}{a vector of variances of the effect sizes.}

\item{n}{a vector of overall sample sizes.}

\item{lCI}{a vector of lower bounds of confidence intervals.}

\item{uCI}{a vector of upper bounds of confidence intervals.}

\item{t}{a vector of t/z-statistics.}

\item{study_names}{an optional argument with the names of the studies.}

\item{data}{a data frame with column names corresponding to the
variable names used to supply data individually.}

\item{transformation}{transformation to be applied to the supplied
effect sizes before fitting the individual models. Defaults to
\code{"fishers_z"}. We highly recommend using \code{"fishers_z"}
transformation since it is the only variance stabilizing measure
and does not bias PET and PEESE style models. The other options are
\code{"cohens_d"}, correlation coefficient \code{"r"} and \code{"logOR"}.
Supplying \code{"none"} will treat the effect sizes as unstandardized and
refrain from any transformations.}

\item{prior_scale}{a scale used to define priors. Defaults to \code{"cohens_d"}.
Other options are \code{"fishers_z"}, correlation coefficient \code{"r"},
and \code{"logOR"}. The prior scale does not need to match the effect sizes measure -
the samples from prior distributions are internally transformed to match the
\code{transformation} of the data. The \code{prior_scale} are corresponds to
the scale of default output, but can be changed within the summary function.}

\item{effect_direction}{the expected direction of the effect. The one-sided
selection sets the weights omega to 1 to significant results in the expected
direction. Defaults to \code{"positive"} (another option is \code{"negative"}).}

\item{priors_effect}{list of prior distributions for the \code{mu} parameter that
will be treated as belonging to the alternative hypothesis. Defaults to \code{
prior(distribution = "normal",   parameters = list(mean = 0, sd = 1))}.}

\item{priors_heterogeneity}{list of prior distributions for the \code{tau} parameter that
will be treated as belonging to the alternative hypothesis. Defaults to \code{
prior(distribution = "invgamma", parameters = list(shape = 1, scale = .15))}.}

\item{priors_bias}{list of prior weight functions for the \code{omega}
parameter that will be treated as belonging to the alternative hypothesis.
Defaults to \code{list(
prior(distribution = "two.sided", parameters = list(alpha = c(1, 1),     steps = c(.05)),      prior_weights = 1/2),
prior(distribution = "two.sided", parameters = list(alpha = c(1, 1, 1),  steps = c(.05, .10)), prior_weights = 1/2)
)}.}

\item{priors_effect_null}{list of prior distributions for the \code{mu} parameter that
will be treated as belonging to the null hypothesis. Defaults to point distribution
with location at 0 (
\code{prior(distribution = "point", parameters = list(location = 0))}).}

\item{priors_heterogeneity_null}{list of prior distributions for the \code{tau} parameter that
will be treated as belonging to the null hypothesis. Defaults to point distribution
with location at 0 (
\code{prior(distribution = "point", parameters = list(location = 0))}).}

\item{priors_bias_null}{list of prior weight functions for the \code{omega} parameter
that will be treated as belonging to the null hypothesis. Defaults to point
distribution with location at 1 (
\code{prior(distribution = "point", parameters = list(location = 0))}).}

\item{chains}{a number of chains of the MCMC algorithm.}

\item{sample}{a number of sampling iterations of the MCMC algorithm.
Defaults to \code{10000}, with a minimum of \code{4000}.}

\item{burnin}{a number of burnin iterations of the MCMC algorithm.
Defaults to \code{5000}.}

\item{thin}{a thinning of the chains of the MCMC algorithm. Defaults to
\code{1}.}

\item{parallel}{whether the individual models should be fitted in parallel.
Defaults to \code{FALSE}. The \code{cores} argument within the \code{control}
list will overwrite the setting if specified to a number higher than 1.}

\item{save}{whether all models posterior distributions should be kept
after obtaining a model-averaged result. Defaults to \code{"all"} which
does not remove anything. Set to \code{"min"} to significantly reduce
the size of final object, however, some model diagnostics \code{\link[=check]{check()}} will
not be available.}

\item{seed}{a seed to be set before model fitting, marginal likelihood
computation, and posterior mixing for exact results reproducibility. Defaults
to \code{NULL} - no seed is set.}

\item{control}{a list of additional arguments for the MCMC algorithm.
Possible options are:
\describe{
\item{autofit}{Whether the models should be refitted until convergence.
Defaults to \code{FALSE}}
\item{max_error}{The target MCMC error for the autofit function. The
argument is passed to \link[coda]{raftery.diag} as 'r'. Defaults to
\code{.01}.}
\item{max_rhat}{The target Rhat error for the autofit function. The
argument is passed to \link[runjags]{add.summary} as 'psrf.target'.
Defaults to \code{1.05}.}
\item{max_time}{A string specifying the maximum fitting time in case
of autofit. Defaults to \code{Inf}. Can be specified as a number and
a unit (Acceptable units include ’seconds’, ’minutes’, ’hours’, ’days’,
’weeks’, or the first letter(s) of each), i.e. \code{"1hr"}.}
\item{adapt}{A number of iterations used for MCMC adaptation. Defaults
to \code{1000}.}
\item{bridge_max_iter}{Maximum number of iterations for the
\link[bridgesampling]{bridge_sampler} function. Defaults to \code{10000}}
\item{allow_max_error}{Maximum allowed MCMC error for a model to be taken
into consideration. The model will be removed from the ensemble if it fails to
achieve the set MCMC error. Defaults to \code{NULL} - no model will be
removed based on MCMC error.}
\item{allow_max_rhat}{Maximum allowed Rhat for a model to be taken into
consideration. Model will be removed from the ensemble if it fails to
achieve the set Rhat. Defaults to \code{NULL} - no model will be removed
based on Rhat.}
\item{allow_min_ESS}{Minimum allowed ESS for a model to be taken into
consideration. Model will be removed from the ensemble if it fails to
achieve the set ESS. Defaults to \code{NULL} - no model will be removed
based on ESS.}
\item{balance_prob}{Whether the prior probability of the removed model
should be redistributed to other models with the same type if possible
(crossing of effect / heterogeneity / publication bias). Defaults to
\code{TRUE}.}
\item{silent}{Whether all fitting messages should be suppressed. Defaults
to \code{FALSE}. Ideal for getting rid of the "full precision may not have
been achieved in pnt{final}'" warning that cannot be suppressed in any
other way.}
\item{boost}{Whether the likelihood functions implemented using the boost
C++ library should be used as the first option. The higher precision of
boost allows to estimate models in difficult cases. Defaults to \code{FALSE}.
The R distributions are used as default and boost is used only if they fail.
Warning: the estimation using boost takes about twice as long.}
\item{cores}{Maximum number of cores to be used for parallel computation. If
\code{parallel == TRUE}, the default number is equal to number of cores - 1,
and 1 (no parallel processing otherwise).}
}}
}
\value{
\code{RoBMA} returns an object of \link[base]{class} \code{"RoBMA"}.
}
\description{
\code{RoBMA} is used to estimate a Robust Bayesian
Meta-Analysis. Either t-statistics (\code{t}) and sample sizes of
the original studies (\code{n} or \code{n1} and \code{n2}), or
effect sizes (\code{d}) and standard errors (\code{se}) can be
used to estimate the model.
}
\details{
The default settings with either t-statistics / Cohen's d effect
sizes and sample sizes / standard errors correspond to the ensemble proposed by
\insertCite{maier2020}{RoBMA}. The \code{vignette("CustomEnsembles")} and
\code{vignette("ReproducingBMA")} vignettes describe how to use \code{\link[=RoBMA]{RoBMA()}} to fit
custom meta-analytic ensembles (see \code{\link[=prior]{prior()}} for more information about prior
distributions). To get help with the error and warning messages,
see \code{vignette("WarningsAndErrors")}.

The RoBMA function first generates models from a combination of the
provided priors for each of the model parameters. Then, the individual models
are fitted using \link[runjags]{autorun.jags} function. A marginal likelihood
is computed using \link[bridgesampling]{bridge_sampler} function. The individual
models are then combined into an ensemble using the posterior model probabilities.

Generic \code{\link[=summary.RoBMA]{summary.RoBMA()}}, \code{\link[=print.RoBMA]{print.RoBMA()}}, and \code{\link[=plot.RoBMA]{plot.RoBMA()}} functions are
provided to facilitate manipulation with the ensemble. A visual check of the
individual model diagnostics can be obtained using the \code{\link[=diagnostics]{diagnostics()}} function.
The fitted model can be further updated or modified by \code{\link[=update.RoBMA]{update.RoBMA()}} function.
}
\examples{
\dontrun{
# using the example data from Anderson et al. 2010 and fitting the default model
# (note that the model can take a while to fit)
fit <- RoBMA(r = Anderson2010$r, n = Anderson2010$n, study_names = Anderson2010$labels)

# in order to speed up the process, we can reduce the default number of chains, iteration,
# and disable the autofit functionality (see ?RoBMA for all possible settings)
fit_faster <- RoBMA(r = Anderson2010$r, n = Anderson2010$n, study_names = Anderson2010$labels,
chains = 2, iter = 5000, control = list(autofit = FALSE))

# RoBMA function allows to use different prior specifications
# for example, change the prior for tau to be half normal and specify one-sided selection only
# on significant p-values (see '?.prior' for all options regarding prior distributions)
fit1 <- RoBMA(r = Anderson2010$r, n = Anderson2010$n, study_names = Anderson2010$labels,
              priors_heterogeneity = prior("normal",
                                 parameters = list(mean = 0, sd = 1),
                                 truncation = list(lower = 0, upper = Inf)),
              priors_bias = prior("one-sided",
                                   parameters = list(cuts = c(.05), alpha = c(1, 1))))

# the priors for the null models can be modified or even omitted in a similar manner,
# allowing to test different (non-nill-null) hypotheses
fit2 <- RoBMA(r = Anderson2010$r, n = Anderson2010$n, study_names = Anderson2010$labels,
              priors_effect_null  = prior("normal",
                                 parameters = list(mean = 0, sd = .1),
                                 truncation = list(lower = -0.1, upper = 0.1)))

# an already fitted RoBMA model can be further updated or modified by using the update function
# for example, the prior model probabilities can be changed after the fitting by
# (but see '?update.RoBMA' for other possibilities including refitting or adding more models)
fit3 <- update(fit2, prior_weights = c(10,1,1,1,1,1,1,1,1,1,1,1))

# we can get a quick overview of the model coefficients just by printing the model
fit

# a more detailed overview using the summary function (see '?summary.RoBMA' for all options)
summary(fit)

# results of the models can be visualized using the plot function (see ?plot.RoBMA for all options)
# for example, the model-averaged mean estimate
plot(fit, parameter = "mu")

# diagnostics for the individual parameters in individual models can be obtained using diagnostics
# function (see 'diagnostics' for all options)
diagnostics(fit, parameter = "mu", type = "chains")
}

}
\references{
\insertAllCited{}
}
\seealso{
\code{\link[=summary.RoBMA]{summary.RoBMA()}}, \code{\link[=update.RoBMA]{update.RoBMA()}}, \code{\link[=prior]{prior()}}, \code{\link[=check_setup]{check_setup()}}
}
