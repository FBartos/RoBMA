% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main.R
\name{RoBMA}
\alias{RoBMA}
\title{Estimate a Robust Bayesian Meta-Analysis}
\usage{
RoBMA(
  t = NULL,
  d = NULL,
  r = NULL,
  y = NULL,
  se = NULL,
  n = NULL,
  n1 = NULL,
  n2 = NULL,
  test_type = "two.sample",
  study_names = NULL,
  mu_transform = if (!is.null(r)) "cohens_d" else NULL,
  priors_mu = prior(distribution = "normal", parameters = list(mean = 0, sd = 1)),
  priors_tau = prior(distribution = "invgamma", parameters = list(shape = 1, scale =
    0.15)),
  priors_omega = list(prior(distribution = "two.sided", parameters = list(alpha = c(1,
    1), steps = c(0.05)), prior_odds = 1/2), prior(distribution = "two.sided", parameters
    = list(alpha = c(1, 1, 1), steps = c(0.05, 0.1)), prior_odds = 1/2)),
  priors_mu_null = prior(distribution = "point", parameters = list(location = 0)),
  priors_tau_null = prior(distribution = "point", parameters = list(location = 0)),
  priors_omega_null = prior(distribution = "point", parameters = list(location = 1)),
  chains = 3,
  iter = 10000,
  burnin = 5000,
  thin = 1,
  control = NULL,
  save = "all",
  seed = NULL
)
}
\arguments{
\item{t}{a vector of t-statistics.}

\item{d}{a vector of effect sizes measured as Cohen's d.}

\item{r}{a vector of effect sizes measured as correlations.}

\item{y}{a vector of unspecified effect sizes.}

\item{se}{a vector of standard errors of the effect sizes.}

\item{n}{a vector of overall sample sizes.}

\item{n1}{a vector of sample sizes for first group.}

\item{n2}{a vector of sample sizes for second group.}

\item{test_type}{a type of test used in the original studies. Options
are \code{"two.sample"} (default) and \code{"one.sample"}. Only available
if \code{d} is supplied.}

\item{study_names}{an optional argument with names of the studies.}

\item{mu_transform}{transformation to be applied to the supplied
effect sizes before fitting the individual models. Defaults to
\code{"cohens_d"} for correlations (another options \code{"fishers_z"}).
Note that priors are specified on the transformed scale and
estimates are transformed back (apart from tau).}

\item{priors_mu}{list of prior distributions for the \code{mu} parameter that
will be treated as belonging to the alternative hypothesis. Defaults to \code{
prior(distribution = "normal",   parameters = list(mean = 0, sd = 1))}.}

\item{priors_tau}{list of prior distributions for the \code{tau} parameter that
will be treated as belonging to the alternative hypothesis. Defaults to \code{
prior(distribution = "invgamma", parameters = list(shape = 1, scale = .15))}.}

\item{priors_omega}{list of prior weight functions for the \code{omega}
parameter that will be treated as belonging to the alternative hypothesis.
Defaults to \code{list(
prior(distribution = "two.sided", parameters = list(alpha = c(1, 1),     steps = c(.05)),      prior_odds = 1/2),
prior(distribution = "two.sided", parameters = list(alpha = c(1, 1, 1),  steps = c(.05, .10)), prior_odds = 1/2)
)}.}

\item{priors_mu_null}{list of prior distributions for the \code{mu} parameter that
will be treated as belonging to the null hypothesis. Defaults to point distribution
with location at 0 (
\code{prior(distribution = "point", parameters = list(location = 0))}).}

\item{priors_tau_null}{list of prior distributions for the \code{tau} parameter that
will be treated as belonging to the null hypothesis. Defaults to point distribution
with location at 0 (
\code{prior(distribution = "point", parameters = list(location = 0))}).}

\item{priors_omega_null}{list of prior weight functions for the \code{omega} parameter
that will be treated as belonging to the null hypothesis. Defaults to point
distribution with location at 1 (
\code{prior(distribution = "point", parameters = list(location = 0))}).}

\item{chains}{a number of chains of the MCMC algorithm.}

\item{iter}{a number of sampling iterations of the MCMC algorithm.
Defaults to \code{10000}, with minimum of \code{4000}.}

\item{burnin}{a number of burnin iterations of the MCMC algorithm.
Defaults to \code{5000}.}

\item{thin}{a thinning of the chains of the MCMC algorithm. Defaults to
\code{1}.}

\item{control}{a list of additional arguments for the MCMC algorithm.
Possible options are:
\describe{
\item{autofit}{Whether the models should be refitted until convergence.
Defaults to \code{TRUE}}
\item{max_rhat}{The maximum acceptable Gelman-Rubin convergence
diagnostic (sometimes referred to as psrf). Defaults to \code{1.05}}
\item{max_time}{A string specifying the maximum fitting time in case
of autofit. Defaults to \code{Inf}. Can be specified as a number and
a unit (Acceptable units include ’seconds’, ’minutes’, ’hours’, ’days’,
’weeks’, or the first letter(s) of each), i.e. \code{"1hr"}.}
\item{adapt}{A number of iterations used for MCMC adaptation. Defaults
to \code{1000}.}
\item{bridge_max_iter}{Maximum number of iterations for the
\link[bridgesampling]{bridge_sampler} function. Defaults to \code{10000}}
\item{allow_max_rhat}{Maximum allowed Rhat for a model to be taken into
consideration. Model will be removed from the ensemble if it fails to
achieve the set Rhat. Defaults to \code{NULL} - no model will be removed
based on Rhat.}
\item{allow_min_ESS}{Minimum allowed ESS for a model to be taken into
consideration. Model will be removed from the ensemble if it fails to
achieve the set ESS. Defaults to \code{NULL} - no model will be removed
based on ESS}
\item{allow_inc_theta}{Whether the diagnostics for theta should be
included into model removal decision. Defaults to \code{NULL} - only
'mu', 'tau', and 'omega' estimates will be taken into account.}
\item{balance_prob}{Whether the prior probability of removed model
should be redistributed to other models with the same type if possible
(crossing of effect / heterogeneity / publication bias). Defaults to
\code{TRUE}.}
\item{silent}{Whether all fitting messages should be suppressed. Defaults
to \code{FALSE}.}
}}

\item{save}{whether all models posterior distributions should be kept
after obtaining a model-averaged result. Defaults to \code{"all"} which
does not remove anything. Set to \code{"min"} to significantly reduce
the size of final object, however, some model diagnostics \code{\link[=check]{check()}} will
not be available.}

\item{seed}{a seed to be set before model fitting, marginal likelihood
computation, and posterior mixing for exact results reproducibility. Defaults
to \code{NULL} - no seed is set.}
}
\value{
\code{RoBMA} returns an object of \link[base]{class} \code{"RoBMA"}.
}
\description{
\code{RoBMA} is used to estimate a Robust Bayesian
Meta-Analysis. Either t-statistics (\code{t}) and sample sizes of
the original studies (\code{n} or \code{n1} and \code{n2}), or
effect sizes (\code{d}) and standard errors (\code{se}) can be
used to estimate the model.
}
\details{
The RoBMA function first generates models from combination of the
provided priors for each of the model parameter. Then, the individual models
are fitted using \link[runjags]{autorun.jags} function. A marginal likelihood
is computed using \link[bridgesampling]{bridge_sampler} function. The individual
models are then combined into an ensemble using posterior model probabilities.

Generic \code{\link[=summary.RoBMA]{summary.RoBMA()}}, \code{\link[=print.RoBMA]{print.RoBMA()}}, and \code{\link[=plot.RoBMA]{plot.RoBMA()}} functions are
provided to facilitate manipulation with the ensemble. A visual check of the
individual model diagnostics can be obtained using the \code{\link[=diagnostics]{diagnostics()}} function.
The fitted model can be further updated or modified by \code{\link[=update.RoBMA]{update.RoBMA()}} function.

See \code{\link[=prior]{prior()}} for more information about possible prior specifications options.
}
\seealso{
\code{\link[=summary.RoBMA]{summary.RoBMA()}}, \code{\link[=update.RoBMA]{update.RoBMA()}}, \code{\link[=prior]{prior()}}, \code{\link[=check_setup]{check_setup()}}
}
